{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Masked AutoEncoder testing\n",
    "In this notebook I will test my  implementation of Masked Autoencoder (MAE).\n",
    "The idea of MAE is masking random patches of the input image and reconstruct the missing pixels. This whole achitecture can be seen in the following figure.\n",
    "![mae](https://user-images.githubusercontent.com/11435359/146857310-f258c86c-fde6-48e8-9cee-badd2b21bd2c.png)\n",
    "\n",
    "\n",
    "We will test: \n",
    "1. Random Masking.\n",
    "2. The MaksedAutoEncoder class.\n",
    "3. The ClassificationMAE class. "
   ],
   "id": "ee0f195e5e095ce8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Import packages\n",
    "import torch\n",
    "import io\n",
    "import urllib.request\n",
    "from architectures.utils import index_sequence\n",
    "from architectures.MaskedAutoEncoder import MaskedAutoEncoder\n",
    "from architectures.Transformer import Transformer\n",
    "from architectures.ClassificationMAE import ClassificationMAE\n",
    "from architectures.utils import random_masking, restore_masked"
   ],
   "id": "e2010af357ccd27b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Download Testing Data\n",
    "\n",
    "def load_from_url(url):\n",
    "    return torch.load(io.BytesIO(urllib.request.urlopen(url).read()))\n",
    "\n",
    "test_data = load_from_url('https://github.com/Berkeley-CS182/cs182hw9/raw/main/test_reference.pt')\n",
    "auto_grader_data = load_from_url('https://github.com/Berkeley-CS182/cs182hw9/raw/main/autograder_student.pt')\n",
    "auto_grader_data['output'] = {}"
   ],
   "id": "8d25f10249b778d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Utilities for Testing\n",
    "def save_auto_grader_data():\n",
    "    torch.save(\n",
    "        {'output': auto_grader_data['output']},\n",
    "        'autograder.pt'\n",
    "    )\n",
    "\n",
    "def rel_error(x, y):\n",
    "    return torch.max(\n",
    "        torch.abs(x - y)\n",
    "        / (torch.maximum(torch.tensor(1e-8), torch.abs(x) + torch.abs(y)))\n",
    "    ).item()\n",
    "\n",
    "def check_error(name, x, y, tol=1e-3):\n",
    "    error = rel_error(x, y)\n",
    "    if error > tol:\n",
    "        print(f'The relative error for {name} is {error}, should be smaller than {tol}')\n",
    "    else:\n",
    "        print(f'The relative error for {name} is {error}')\n",
    "\n",
    "def check_acc(acc, threshold):\n",
    "    if acc < threshold:\n",
    "        print(f'The accuracy {acc} should >= threshold accuracy {threshold}')\n",
    "    else:\n",
    "        print(f'The accuracy {acc} is better than threshold accuracy {threshold}')"
   ],
   "id": "cbb5b2659ea227de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(index_sequence(\n",
    "    torch.tensor([\n",
    "        [0.0, 0.1, 0.2],\n",
    "        [1.0, 1.1, 1.2]\n",
    "    ], dtype=torch.float),\n",
    "    torch.tensor([\n",
    "        [0, 2],\n",
    "        [0, 1]\n",
    "    ], dtype=torch.long)\n",
    "))"
   ],
   "id": "efab91efe06b3a09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Testing random masking",
   "id": "9bb8d5eda2e0b6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(index_sequence(\n",
    "    torch.tensor([\n",
    "        [0.0, 0.1, 0.2],\n",
    "        [1.0, 1.1, 1.2]\n",
    "    ], dtype=torch.float),\n",
    "    torch.tensor([\n",
    "        [0, 2],\n",
    "        [0, 1]\n",
    "    ], dtype=torch.long)\n",
    "))"
   ],
   "id": "1915c65df751be6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x, ids_shuffle = test_data['input']['random_masking']\n",
    "kept, mask, ids_restore = random_masking(x, 4, ids_shuffle)\n",
    "kept_t, mask_t, ids_restore_t = test_data['output']['random_masking']\n",
    "check_error('random_masking: kept', kept, kept_t)\n",
    "check_error('random_masking: mask', mask, mask_t)\n",
    "check_error('random_masking: ids_restore', ids_restore, ids_restore_t)\n",
    "\n",
    "x, ids_shuffle = auto_grader_data['input']['random_masking']\n",
    "kept, mask, ids_restore = random_masking(x, 4, ids_shuffle)\n",
    "auto_grader_data['output']['random_masking'] = (kept, mask, ids_restore)\n",
    "save_auto_grader_data()\n",
    "\n",
    "kept_x, masked_x, ids_restore = test_data['input']['restore_masked']\n",
    "restored = restore_masked(kept_x, masked_x, ids_restore)\n",
    "check_error('restore_masked', restored, test_data['output']['restore_masked'])\n",
    "\n",
    "kept_x, masked_x, ids_restore = auto_grader_data['input']['restore_masked']\n",
    "restored = restore_masked(kept_x, masked_x, ids_restore)\n",
    "auto_grader_data['output']['restore_masked'] = (kept, mask, ids_restore)\n",
    "save_auto_grader_data()"
   ],
   "id": "59c2e20503e29485"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Testing MAE implementation",
   "id": "c0cbe29a035497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Test your implementation\n",
    "model = MaskedAutoEncoder(\n",
    "    Transformer(embedding_dim=256, n_layers=4),\n",
    "    Transformer(embedding_dim=128, n_layers=2),\n",
    ")\n",
    "\n",
    "model.load_state_dict(test_data['weights']['MaskedAutoEncoder'])\n",
    "images, ids_shuffle = test_data['input']['MaskedAutoEncoder.forward_encoder']\n",
    "encoder_embeddings_t, mask_t, ids_restore_t = test_data['output']['MaskedAutoEncoder.forward_encoder']\n",
    "encoder_embeddings, mask, ids_restore = model.forward_encoder(\n",
    "    images, ids_shuffle\n",
    ")\n",
    "\n",
    "check_error(\n",
    "    'MaskedAutoEncoder.forward_encoder: encoder_embeddings',\n",
    "    encoder_embeddings, encoder_embeddings_t, .008\n",
    ")\n",
    "check_error(\n",
    "    'MaskedAutoEncoder.forward_encoder: mask',\n",
    "    mask, mask_t\n",
    ")\n",
    "check_error(\n",
    "    'MaskedAutoEncoder.forward_encoder: ids_restore',\n",
    "    ids_restore, ids_restore_t\n",
    ")\n",
    "\n",
    "encoder_embeddings, ids_restore = test_data['input']['MaskedAutoEncoder.forward_decoder']\n",
    "decoder_output_t = test_data['output']['MaskedAutoEncoder.forward_decoder']\n",
    "decoder_output = model.forward_decoder(encoder_embeddings, ids_restore)\n",
    "check_error(\n",
    "    'MaskedAutoEncoder.forward_decoder',\n",
    "    decoder_output,\n",
    "    decoder_output_t, .03\n",
    ")\n",
    "\n",
    "images = test_data['input']['MaskedAutoEncoder.forward_encoder_representation']\n",
    "encoder_representations_t = test_data['output']['MaskedAutoEncoder.forward_encoder_representation']\n",
    "encoder_representations = model.forward_encoder_representation(images)\n",
    "check_error(\n",
    "    'MaskedAutoEncoder.forward_encoder_representation',\n",
    "    encoder_representations,\n",
    "    encoder_representations_t, .01\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = MaskedAutoEncoder(\n",
    "    Transformer(embedding_dim=256, n_layers=4),\n",
    "    Transformer(embedding_dim=128, n_layers=2),\n",
    ")\n",
    "\n",
    "model.load_state_dict(auto_grader_data['weights']['MaskedAutoEncoder'])\n",
    "images, ids_shuffle = auto_grader_data['input']['MaskedAutoEncoder.forward_encoder']\n",
    "auto_grader_data['output']['MaskedAutoEncoder.forward_encoder'] = model.forward_encoder(\n",
    "    images, ids_shuffle\n",
    ")\n",
    "\n",
    "encoder_embeddings, ids_restore = auto_grader_data['input']['MaskedAutoEncoder.forward_decoder']\n",
    "auto_grader_data['output']['MaskedAutoEncoder.forward_decoder'] = model.forward_decoder(encoder_embeddings, ids_restore)\n",
    "\n",
    "images = auto_grader_data['input']['MaskedAutoEncoder.forward_encoder_representation']\n",
    "auto_grader_data['output']['MaskedAutoEncoder.forward_encoder_representation'] = model.forward_encoder_representation(images)\n",
    "save_auto_grader_data()\n"
   ],
   "id": "89831ab9c24016e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Testing Classification MAE implementation",
   "id": "6a43513d583b9e16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Test your implementation\n",
    "model = ClassificationMAE(\n",
    "    10,\n",
    "    MaskedAutoEncoder(\n",
    "        Transformer(embedding_dim=256, n_layers=4),\n",
    "        Transformer(embedding_dim=128, n_layers=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "model.load_state_dict(test_data['weights']['ClassificationMAE'])\n",
    "\n",
    "check_error(\n",
    "    'ClassificationMAE.forward',\n",
    "    model(test_data['input']['ClassificationMAE.forward']),\n",
    "    test_data['output']['ClassificationMAE.forward']\n",
    ")\n",
    "\n",
    "model = ClassificationMAE(\n",
    "    10,\n",
    "    MaskedAutoEncoder(\n",
    "        Transformer(embedding_dim=256, n_layers=4),\n",
    "        Transformer(embedding_dim=128, n_layers=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "model.load_state_dict(auto_grader_data['weights']['ClassificationMAE'])\n",
    "auto_grader_data['output']['ClassificationMAE.forward'] = model(\n",
    "    auto_grader_data['input']['ClassificationMAE.forward']\n",
    ")\n",
    "save_auto_grader_data()"
   ],
   "id": "6f04407c4aac91e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
